{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e534759b-3b65-46f5-b2ac-fc20a5cb03ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: accelerate in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (1.4.0)\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: filelock in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: psutil in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch pandas tqdm accelerate fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2337c28e-5d6a-4cae-bd19-36c45a90c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from TextToCypherDataLoader import Text2CypherDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Enable TensorFloat32 for faster matrix operations\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = \"/work/pi_wenlongzhao_umass_edu/9/dpatel/\"\n",
    "MODEL_PATH = \"/datasets/ai/\"\n",
    "DEEPSEEK_DISTILL_LLAMA_70B_PATH = \"deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Llama-70B/snapshots/0d6d11a6ea1187363aa7b78543f824fc02e06b14\"\n",
    "DEEPSEEK_DISTILL_QWEN_7B_PATH = \"deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-7B/snapshots/6602cadec947dbb53e64f3d8d6425320b2197247\"\n",
    "DEEPSEEK_DISTILL_QWEN_32B_PATH = \"deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-32B/snapshots/3865e12a1eb7cbd641ab3f9dfc28c588c6b0c1e9\"\n",
    "LLAMA_3_70B_INSTRUCT = \"llama3/hub/Meta-Llama-3-70B-Instruct/original\"\n",
    "\n",
    "DEEPSEEK_DISTILL_LLAMA_70B = os.path.join(MODEL_PATH, DEEPSEEK_DISTILL_LLAMA_70B_PATH)\n",
    "DEEPSEEK_DISTILL_QWEN_7B = os.path.join(MODEL_PATH, DEEPSEEK_DISTILL_QWEN_7B_PATH)\n",
    "DEEPSEEK_DISTILL_QWEN_32B = os.path.join(MODEL_PATH, DEEPSEEK_DISTILL_QWEN_32B_PATH)\n",
    "\n",
    "dataset = load_dataset(\"neo4j/text2cypher-2024v1\")[\"train\"].shuffle(seed=42).select(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa252b43-f9b3-4f2b-92d1-862c97aabd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    # (DEEPSEEK_DISTILL_QWEN_7B, \"DeepSeek Distill QWEN 7B\"),\n",
    "    # (DEEPSEEK_DISTILL_LLAMA_70B, \"DeepSeek R1 Distill Llama 70B\"),\n",
    "    (DEEPSEEK_DISTILL_QWEN_32B, \"DeepSeek Distill QWEN 32B\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1baa65f-bf72-4193-a1ef-aac75372dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7d1ebf-5cbe-4203-abf3-4e8d1a8c3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def generate_cypher(batch_questions, batch_schemas, model, tokenizer):\n",
    "    batch_inputs = [\n",
    "        (\n",
    "            \"Convert this question into a **valid** Cypher query.\\n\\n\"\n",
    "            f\"Question: {question}\\n\"\n",
    "            f\"Schema: {schema}\\n\"\n",
    "            \"Answer:\\n\"\n",
    "        ) for question, schema in zip(batch_questions, batch_schemas)\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer(batch_inputs, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=512, \n",
    "            do_sample=False, \n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    return tokenizer.batch_decode(output_tokens.cpu(), skip_special_tokens=True)\n",
    "\n",
    "def extract_cypher(output_text):\n",
    "    matches = re.findall(r\"```cypher\\n(.*?)\\n```\", output_text, re.DOTALL)\n",
    "    return matches[-1].strip() if matches else output_text.strip()  # Assume the last query returned is the correct one\n",
    "\n",
    "def normalize_cypher(query):\n",
    "    return \" \".join(query.lower().split())\n",
    "\n",
    "def is_exact_match(predicted_cypher, true_cypher):\n",
    "    return normalize_cypher(predicted_cypher) == normalize_cypher(true_cypher)\n",
    "\n",
    "def similarity_score(predicted_cypher, true_cypher):\n",
    "    # Check for similariy between the query instead of exact match\n",
    "    return fuzz.ratio(normalize_cypher(predicted_cypher), normalize_cypher(true_cypher))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcee445c-7a57-4661-8566-bb37ad263e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baseline(train_loader, model, tokenizer, name):\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    exact_matches = 0\n",
    "    similarity_scores = []\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Generating Cypher Queries - {name}\"):\n",
    "        batch_questions = batch[\"question\"]\n",
    "        batch_schemas = batch[\"schema\"]\n",
    "        batch_true_cyphers = batch[\"cypher\"]\n",
    "\n",
    "        predicted_cyphers = generate_cypher(batch_questions, batch_schemas, model, tokenizer)\n",
    "\n",
    "        for true_cypher, raw_predicted_cypher in zip(batch_true_cyphers, predicted_cyphers):\n",
    "            predicted_cypher = extract_cypher(raw_predicted_cypher)\n",
    "            if is_exact_match(predicted_cypher, true_cypher):\n",
    "                exact_matches += 1\n",
    "            similarity_scores.append(similarity_score(predicted_cypher, true_cypher))\n",
    "            total_samples += 1\n",
    "            \n",
    "    exact_match_accuracy = (exact_matches / total_samples) * 100\n",
    "    avg_similarity = sum(similarity_scores) / total_samples\n",
    "\n",
    "    new_result = {\n",
    "        \"Model Name\": name,\n",
    "        \"Exact Match Accuracy\": f\"{exact_match_accuracy:.2f}%\",\n",
    "        \"Average Similarity Score\": f\"{avg_similarity:.2f}\",\n",
    "        \"Total Samples\": total_samples\n",
    "    }\n",
    "\n",
    "    OUTPUT_PATH = os.path.join(DATASET_PATH, \"zero_shot_baseline_results.csv\")\n",
    "    if os.path.exists(OUTPUT_PATH):\n",
    "        df = pd.read_csv(OUTPUT_PATH)\n",
    "        df = pd.concat([df, pd.DataFrame([new_result])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame([new_result])\n",
    "    \n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "\n",
    "    print(f\"✅ Results saved to {OUTPUT_PATH} for model {name}\")\n",
    "    print(f\"✅ Exact Match Accuracy: {exact_matches}/{total_samples} ({exact_match_accuracy:.2f}%)\")\n",
    "    print(f\"✅ Average Similarity Score: {avg_similarity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4c954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5eb42dafc54cc586ff9f847e5a7c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Generating Cypher Queries - DeepSeek Distill QWEN 32B:   0%|          | 0/1 [00:00<?, ?it/s]/home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/dhrumeenkish_umass_edu/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model_path, model_name in MODEL_LIST:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    train_dataset = Text2CypherDataset(dataset, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    generate_baseline(train_loader, model, tokenizer, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f0a15-f00c-4dc3-bd99-7574d8f79011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(OUTPUT_PATH)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
