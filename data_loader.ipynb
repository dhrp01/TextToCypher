{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc2cd93-4a53-4c18-8b84-db68cf85e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.49.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./.local/lib/python3.11/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in ./.local/lib/python3.11/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.local/lib/python3.11/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.11/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /modules/apps/ood/jupyterlab-matlab/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets torch transformers sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9ce12-0028-42fd-9c2d-817a1bbad9a7",
   "metadata": {},
   "source": [
    "Load dataset [neo4j/text2cypher-2024v1](https://huggingface.co/datasets/neo4j/text2cypher-2024v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dd6c8a-ccfc-4b10-b5b8-b5fa51fbb47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"neo4j/text2cypher-2024v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff12059-2665-4ea9-8c6f-6ac6c8b4ae95",
   "metadata": {},
   "source": [
    "Dataset columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4a99239-0a6d-42b8-a0ea-2a4e79a92376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: {'train': 6, 'test': 6}, \n",
      "Columns names: {'train': ['question', 'schema', 'cypher', 'data_source', 'instance_id', 'database_reference_alias'], 'test': ['question', 'schema', 'cypher', 'data_source', 'instance_id', 'database_reference_alias']},\n",
      "Dataset size: {'train': (39554, 6), 'test': (4833, 6)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns: {dataset.num_columns}, \\nColumns names: {dataset.column_names},\\nDataset size: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60e589-002d-45ee-b64a-71806f6d9f4b",
   "metadata": {},
   "source": [
    "Print a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db08a259-5ae3-40d4-9d76-01e3f670f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'schema', 'cypher', 'data_source', 'instance_id', 'database_reference_alias'],\n",
      "        num_rows: 39554\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'schema', 'cypher', 'data_source', 'instance_id', 'database_reference_alias'],\n",
      "        num_rows: 4833\n",
      "    })\n",
      "})\n",
      "{'question': 'Which 3 countries have the most entities linked as beneficiaries in filings?', 'schema': 'Node properties:\\n- **Country**\\n  - `location`: POINT \\n  - `code`: STRING Example: \"AFG\"\\n  - `name`: STRING Example: \"Afghanistan\"\\n  - `tld`: STRING Example: \"AF\"\\n- **Filing**\\n  - `begin`: DATE_TIME Min: 2000-02-08T00:00:00Z, Max: 2017-09-05T00:00:00Z\\n  - `end`: DATE_TIME Min: 2000-02-08T00:00:00Z, Max: 2017-11-03T00:00:00Z\\n  - `originator_bank_id`: STRING Example: \"cimb-bank-berhad\"\\n  - `sar_id`: STRING Example: \"3297\"\\n  - `beneficiary_bank`: STRING Example: \"Barclays Bank Plc\"\\n  - `filer_org_name_id`: STRING Example: \"the-bank-of-new-york-mellon-corp\"\\n  - `originator_bank_country`: STRING Example: \"Singapore\"\\n  - `beneficiary_bank_country`: STRING Example: \"United Kingdom\"\\n  - `filer_org_name`: STRING Example: \"The Bank of New York Mellon Corp.\"\\n  - `originator_iso`: STRING Example: \"SGP\"\\n  - `beneficiary_bank_id`: STRING Example: \"barclays-bank-plc-london-england-gbr\"\\n  - `origin_lat`: STRING Example: \"1.3667\"\\n  - `origin_lng`: STRING Example: \"103.8\"\\n  - `end_date_format`: STRING Example: \"2015-09-25T00:00:00Z\"\\n  - `begin_date_format`: STRING Example: \"2015-03-25T00:00:00Z\"\\n  - `originator_bank`: STRING Example: \"CIMB Bank Berhad\"\\n  - `beneficiary_lat`: STRING Example: \"54\"\\n  - `beneficiary_iso`: STRING Example: \"GBR\"\\n  - `beneficiary_lng`: STRING Example: \"-2\"\\n  - `begin_date`: STRING Example: \"Mar 25, 2015\"\\n  - `id`: STRING Example: \"223254\"\\n  - `end_date`: STRING Example: \"Sep 25, 2015\"\\n  - `amount`: INTEGER Min: 1.18, Max: 2721000000\\n  - `number`: INTEGER Min: 1, Max: 174\\n- **Entity**\\n  - `id`: STRING Example: \"the-bank-of-new-york-mellon-corp\"\\n  - `location`: POINT \\n  - `name`: STRING Example: \"The Bank of New York Mellon Corp.\"\\n  - `country`: STRING Example: \"CHN\"\\nRelationship properties:\\n\\nThe relationships:\\n(:Filing)-[:BENEFITS]->(:Entity)\\n(:Filing)-[:CONCERNS]->(:Entity)\\n(:Filing)-[:ORIGINATOR]->(:Entity)\\n(:Entity)-[:FILED]->(:Filing)\\n(:Entity)-[:COUNTRY]->(:Country)', 'cypher': 'MATCH (f:Filing)-[:BENEFITS]->(e:Entity)-[:COUNTRY]->(c:Country) WITH c.name AS country, COUNT(e) AS entityCount ORDER BY entityCount DESC LIMIT 3 RETURN country, entityCount', 'data_source': 'neo4jLabs_synthetic_gpt4o', 'instance_id': 'instance_id_41185', 'database_reference_alias': 'neo4jlabs_demo_db_fincen'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a68225d-b592-4110-8881-f522ba9142b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884384ac-5422-491a-aeba-0383893c3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2CypherDataset(Dataset):\n",
    "    def __init__(self, dataset_split, tokenizer, max_length=512):\n",
    "        self.dataset = dataset_split\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.dataset[idx]\n",
    "        question = data_point[\"question\"]  # User's natural language question\n",
    "        schema = data_point[\"schema\"]  # Database schema details\n",
    "        database_reference_alias = data_point[\"database_reference_alias\"] # Database alias name, might be useful in subgraph or cross-domain.\n",
    "        cypher_query = data_point[\"cypher\"]  # Target Cypher query\n",
    "\n",
    "        # Combine question and schema as input\n",
    "        input_text = f\"Question: {question} Schema: {schema} Database Refenerce Alias: {database_reference_alias}\"\n",
    "\n",
    "        # Tokenize input (question + schema) and output (cypher query)\n",
    "        inputs = self.tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        outputs = self.tokenizer(cypher_query, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": outputs[\"input_ids\"].squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77910d4-e951-4c3d-9c08-137c10d3185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "train_dataset = Text2CypherDataset(dataset[\"train\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aed7b38-0d6f-42d3-8b9e-dd2e2bee335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[11860,    10, 11677,  ...,    26,     2,     1],\n",
      "        [11860,    10,  4073,  ...,     0,     0,     0],\n",
      "        [11860,    10,  4073,  ..., 21342, 22034,     1],\n",
      "        ...,\n",
      "        [11860,    10,  9778,  ...,     0,     0,     0],\n",
      "        [11860,    10,  6792,  ...,  6306,    10,     1],\n",
      "        [11860,    10,   363,  ...,   226,    40,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[  283, 29572,    41,  ...,     0,     0,     0],\n",
      "        [  283, 29572,    41,  ...,     0,     0,     0],\n",
      "        [  283, 29572,    41,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  283, 29572,    41,  ...,     0,     0,     0],\n",
      "        [  283, 29572,    41,  ...,     0,     0,     0],\n",
      "        [  283, 29572,    41,  ...,     0,     0,     0]])}\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Sample batch\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d58e73-ca32-4303-9b88-175973d45744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
